{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple neural net for XOR operation\n",
    "+ Simple 1-layer neural network to test XOR (exclusive OR) operation.\n",
    "+ XOR function is not achievable with single layer neural net, as perceptron.\n",
    "+ Here, using sigmoid, it is shown that it not feasible to train weights which could make XOR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "eta = 1.0 # learning rate\n",
    "epoch = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "+ 1-layer neural network sigmoid activation function\n",
    "+ loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "class neuralnetwork:\n",
    "    # neural network model\n",
    "    \n",
    "    def __init__(self, x, w, y):\n",
    "        self.inputs  = x\n",
    "        self.weights = w               \n",
    "        self.target  = y\n",
    "        self.output  = np.zeros(self.target.shape)\n",
    "\n",
    "    def forwardproc(self):\n",
    "        # forward processing of inputs and weights using sigmoid activation function \n",
    "        self.output = sigmoid(np.dot(self.weights, self.inputs.T))\n",
    "\n",
    "    def backprop(self):\n",
    "        # backward processing of appling the chain rule to find derivative of the loss function with respect to weights\n",
    "        dw = (self.output - self.target) * self.inputs\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights -= eta * dw\n",
    "\n",
    "    def predict(self, x):\n",
    "        # predict the output for a given input x\n",
    "        return (sigmoid(np.dot(self.weights, x.T)))\n",
    "        \n",
    "\n",
    "    def calculaterror(self):\n",
    "        # calculate error\n",
    "        error = self.target - self.output\n",
    "        print(\"Output: \", self.output)\n",
    "#        print(\"weight1: \", self.weights[0,0])\n",
    "        return str(abs(error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusive OR Operation\n",
    "+ Input and target data are defined for Exclusive OR operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # data normalization on number of rooms and age\n",
    "    inputdata = [[0.0, 0.0],\n",
    "                 [0.0, 1.0],\n",
    "                 [1.0, 0.0],\n",
    "                 [1.0, 1.0]\n",
    "                 ]\n",
    "    weights = np.random.rand(1, 2)  \n",
    "    targetvalue = [[0.0],  \n",
    "                   [1.0],\n",
    "                   [1.0],\n",
    "                   [0,0]\n",
    "                   ]  \n",
    "  \n",
    "    # training \n",
    "    for i in range(epoch):\n",
    "\n",
    "        j = random.randint(0, len(inputdata) - 1)\n",
    "        x = np.array([inputdata[j]])\n",
    "        print(x)\n",
    "        t = np.array([targetvalue[j]])\n",
    "        print(t)\n",
    "        if i == 0: w = weights\n",
    "        else: w = nn.weights          \n",
    "        print(\"Adjusted Weights 1:\", w)\n",
    "      \n",
    "        nn = neuralnetwork(x, w, t)\n",
    "        eta *= 0.95  # decreasing learning rate\n",
    "\n",
    "        for i in range(1000):\n",
    "            nn.forwardproc()\n",
    "            nn.backprop()\n",
    "            if (i % 100) == 0:\n",
    "                print(\"Error: \", nn.calculaterror())\n",
    "        \n",
    "        print(\"Output:\", nn.output)\n",
    "        print(\"Adjusted Weights 2:\", nn.weights)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification \n",
    "+ The results show that the XOR function is not achievable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the output with the adjusted weights\n",
    "    x1 = np.array([[0.0, 0.0]])\n",
    "    print (\"Output for the input data [0.0, 0.0]:\", nn.predict(x1))\n",
    "    x2 = np.array([[0.0, 1.0]])\n",
    "    print (\"Output for the input data [0.0, 1.0]:\", nn.predict(x2))\n",
    "    x3 = np.array([[1.0, 0.0]])\n",
    "    print (\"Output for the input data [1.0, 0.0]:\", nn.predict(x3))\n",
    "    x4 = np.array([[1.0, 1.0]])\n",
    "    print (\"Output for the input data [1.0, 1.0]:\", nn.predict(x4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
