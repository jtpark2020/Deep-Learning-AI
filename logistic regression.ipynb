{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "+ Simple 1-layer neural network with SGD optimization for logistic regression.\n",
    "+ Predict class fail or pass  with information on number of lectures attendance and hours spent on the final project.\n",
    "+ Data: pass with 4 lectures taken and 10 hours of the final project, but fail with 10 lectures and 3  hours.\n",
    "+ Problem: Will I pass with 6 lectures taken with 4 hours for the final project ?\n",
    "+ It is noted that the derivative of weights are the same as that of linear regression.\n",
    "+ The only difference with the code of linear regression is the sigmoid function for forward processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "eta = 1.0 # learning rate\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model for Logistic Regression\n",
    "+ Single layer neural network with logistic function.\n",
    "+ In forward processing, it uses sigmoid activation function. \n",
    "+ The CE (cross-entropy) loss function is used for loss evaluation.\n",
    "+ In backward processing, delta = output - target. It is indentical to that of neural net for linear regression \n",
    "+ although the loss and activation functions are different.\n",
    "+ Refer to the course note for derivation of delta equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "class neuralnetwork:\n",
    "    # neural network model\n",
    "    \n",
    "    def __init__(self, x, w, y):\n",
    "        self.inputs  = x\n",
    "        self.weights = w               \n",
    "        self.target  = y\n",
    "        self.output  = np.zeros(self.target.shape)\n",
    "\n",
    "    def forwardproc(self):\n",
    "        # forward processing of inputs and weights using sigmoid activation function \n",
    "        self.output = sigmoid(np.dot(self.weights, self.inputs.T))\n",
    "\n",
    "    def backprop(self):\n",
    "        # backward processing of appling the chain rule to find derivative of the loss function with respect to weights\n",
    "        dw = (self.output - self.target) * self.inputs\n",
    "\n",
    "        # update the weights with the derivative of the loss function\n",
    "        self.weights -= eta * dw\n",
    "\n",
    "    def predict(self, x):\n",
    "        # predict the output for a given input x\n",
    "        return (sigmoid(np.dot(self.weights, x.T)))\n",
    "        \n",
    "    def calculaterror(self):\n",
    "        # calculate error\n",
    "        error = -self.target * math.log(self.output) - (1-self.target) * math.log(1-self.output)\n",
    "        return abs(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD (Stochastic Gradient Descent) Optimization\n",
    "+ Train the neural net with SGD optimization.\n",
    "+ In SGD, each input data is trained separately with other input data.\n",
    "+ After training, the weights of the neural network are adjusted to generate the target data for the given input data.\n",
    "+ Check how the loss decreases as the iterations increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # data normalization on number of rooms and age\n",
    "    inputdata = [[.4, 1.0],\n",
    "                 [1.0, .3]]\n",
    "    weights = np.random.rand(1, 2)  \n",
    "    targetvalue = [[1.0],  # pass\n",
    "                   [0.0]]  # fail\n",
    "  \n",
    "    # training \n",
    "    for i in range(epoch):\n",
    "\n",
    "        j = random.randint(0, len(inputdata) - 1)\n",
    "        x = np.array([inputdata[j]])\n",
    "        print(x)\n",
    "        t = np.array([targetvalue[j]])\n",
    "        print(t)\n",
    "        if i == 0: w = weights\n",
    "        else: w = nn.weights          \n",
    "        print(\"Adjusted Weights 1:\", w)\n",
    "      \n",
    "        nn = neuralnetwork(x, w, t)\n",
    "        eta *= 0.95  # decreasing learning rate\n",
    "\n",
    "        for i in range(1000):\n",
    "            nn.forwardproc()\n",
    "            nn.backprop()\n",
    "            if (i % 100) == 0:\n",
    "                print(\"Error: \", nn.calculaterror())\n",
    "        \n",
    "        print(\"Output:\", nn.output)\n",
    "        print(\"Adjusted Weights 2:\", nn.weights)\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Prediction\n",
    "+ After training, you can verify that the required target is generated for a given input data.\n",
    "+ During testing phase, new input data is feeded to check the output.\n",
    "+ With new input data, the output is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # verify the output with the adjusted weights\n",
    "    x1 = np.array([[0.4, 1.0]])\n",
    "    print (\"Output for the input data [.4, 1.0]:\", nn.predict(x1))\n",
    "    x2 = np.array([[1.0, 0.3]])\n",
    "    print (\"Output for the input data [1.0, 0.3]:\", nn.predict(x2))\n",
    "    \n",
    "    # predicting and testing the output for a given input data\n",
    "    x_prediction = np.array([[0.6, 0.4]])\n",
    "    predicted_output = nn.predict(x_prediction)\n",
    "    print(\"Predicted data based on trained weights: \")\n",
    "    print(\"Input (scaled): \", x_prediction)\n",
    "    print(\"Output: \", predicted_output)\n",
    "\n",
    "    x_prediction = np.array([[0.5, 0.5]])\n",
    "    predicted_output = nn.predict(x_prediction)\n",
    "    print(\"Predicted data based on trained weights: \")\n",
    "    print(\"Input (scaled): \", x_prediction)\n",
    "    print(\"Output: \", predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
